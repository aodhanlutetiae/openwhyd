{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé - outils et résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on cherche des récommendations sur le log des chansons écoutées, mais suite à un remaniement qui attribue une \n",
    "note (entre 0 et 5) à chaque chanson pour chaque utilisateur. (Remaniement effectué par https://github.com/Patouche). Ce remaniement semble avoir rassemblé les 'doublons' (doublon: un utilisateur écoute chanson x un jour, le réécoute le lendemain) pour que chaque paire utilisateur--chanson paraisse uniquement maintenant une fois, avec son score.\n",
    "\n",
    "OUTILS: library Surprise\n",
    "\n",
    "RESULTATS\n",
    "\n",
    "1. KNNwithMeans - plus des utilisateurs se rassemblent dans leur consomation, plus ils devraient s'échanger de chansons.\n",
    "On arrive à prédire un score pour une chanson, dans le context d'un utilisateur, et sur (je crois) une échelle de 0 à 5, genre (pour une chanson très appréciée, et une autre peu appréciée):\n",
    "user 0 & chanson 55915: 4.52 est \n",
    "user 0 & chanson 78257: 0.37 est\n",
    "- mais comme ces données viennent comme un élément à l'intérieur d'un object Surprise, je ne vois pas encore \n",
    "comment exploiter cet outil. Il faudrait d'abord isoler le score 'est' d'une longue chaîne de résultats, et ensuite...mettre un boucle à tourner pour prédire chaque score pour un utilisateur? Très peu efficace.\n",
    "\n",
    "2. Une fois les ensembles 'train' et 'test' établis à partir de notre log, on peut comparer des différents algos\n",
    "pris de Surprise. On a simplement pris KNNwithMeans mais apparemment c'est BaselineOnly qui a le plus petit RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importer et remanier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from surprise import KNNBasic\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169746, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>count_score</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ghASliN5bAI</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y_goHl-GuNk</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AuFiBjNTB9o</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tSv04ylc6To</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XdBlbR3z1jE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          song  count_score  user_id\n",
       "0  ghASliN5bAI            5        0\n",
       "1  y_goHl-GuNk            4        0\n",
       "2  AuFiBjNTB9o            4        0\n",
       "3  tSv04ylc6To            3        0\n",
       "4  XdBlbR3z1jE            2        0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the log with its 'scores' derived by patouche\n",
    "log = pd.read_csv('.CSV FILE LOCATION')\n",
    "\n",
    "# rename the 'count' column because 'count' is a method in python libraries\n",
    "log.rename(columns = {'song_id':'song','count':'count_score'}, inplace = True)\n",
    "\n",
    "print(log.shape)\n",
    "log.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changer le type de la colonne 'song' à 'catégorie'\n",
    "log['song'] = log['song'].astype(\"category\")\n",
    "\n",
    "# créer une colonne 'song ID' qui sera plus facile à manipuler que les strings youtube qui font 'nom'\n",
    "log['song_id'] = log['song'].cat.codes\n",
    "\n",
    "# changer le type de song_id aussi pour que la colonne soit 'catégorie'\n",
    "log.song_id = log.song_id.astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169746 entries, 0 to 169745\n",
      "Data columns (total 4 columns):\n",
      "song           169746 non-null category\n",
      "count_score    169746 non-null int64\n",
      "user_id        169746 non-null int64\n",
      "song_id        169746 non-null category\n",
      "dtypes: category(2), int64(2)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remanier l'ordre des colonnes pour mieux suivre la logique qui sera appliquée plus bas\n",
    "\n",
    "log = log[['user_id', 'song_id', 'count_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>count_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>78600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14553</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id song_id  count_score\n",
       "0        0   55915            5\n",
       "1        0   78600            4\n",
       "2        0   14553            4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kerpanic KNNwithMeans (from surprise) - explicit User User collaborative filtering\n",
    "\n",
    "https://kerpanic.wordpress.com/2018/03/26/a-gentle-guide-to-recommender-systems-with-surprise/\n",
    "\n",
    "    USER:USER\n",
    "    The output is the prediction of user u’s rating on item i:\n",
    "    si on donnait chanson X à utilisateur, que dirait elle?\n",
    "    We utilize the similarity measure between user u and user v in this case.\n",
    "    \n",
    "    ITEM:ITEM - DO NOT RUN, TAKES FOREVER / HANGS. I DONT KNOW WHY\n",
    "    Instead of using user similarity, we use item similarity measure to calculate the prediction.\n",
    "    Ssimilarity is now between item i and item j, instead of user u and v as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1211e5128>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# on crée / définit un lecteur en précisant l'échelle de notes\n",
    "reader = Reader(rating_scale = (0, 5))\n",
    "\n",
    "# on définit 'data' qui prendra comme paramètres les colonnes utilisateur, chanson et score (et le lecteur)\n",
    "data = Dataset.load_from_df(log[['user_id', 'song_id', 'count_score']], reader=reader)\n",
    "\n",
    "# on divise le data pour garder 15% pour la partie test\n",
    "trainset, testset = train_test_split(data, test_size=.15)\n",
    "\n",
    "# Use user_based true/false to switch between user-based or item-based collaborative filtering\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "\n",
    "# on utilise la partie 'training' pour former l'algo sur notre log\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 1273       item: 73445      r_ui = 4.00   est = 5.00   {'actual_k': 1, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1273, iid=73445, r_ui=4, est=5, details={'actual_k': 1, 'was_impossible': False})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avec l'algo 'formé' sur notre log, on peut demander des prédictions en précisant des utilisateurs et \n",
    "# chansons et en utilisant algo.predict\n",
    "\n",
    "uid = 1273  # utilisateur 102\n",
    "iid = 73445  # chanson 2\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose = True)\n",
    "pred\n",
    "\n",
    "# résultat: estimé 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notons les scores rendu par l'algo quand on demande des chansons aimé / mal aimé par les utilisateurs\n",
    "\n",
    "user 0 / chanson 55915 (score 5) gives 4.52 est\n",
    "user 0 / chanson 78257 (score 1) gives 0.37 est\n",
    "user 1270 / chanson 18125 (score 5) gives 2 est\n",
    "user 1273 / chanson 73445 (score 5) gives 5 est\n",
    "user 1274 / chanson 61382 (score 0) gives 0.43 est\n",
    "user 1274 / chanson 60518 (score 5) gives 5 est\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. choisir son algo - d'abord notre KNNwithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.85969049, 0.86859054, 0.87027891, 0.84736084, 0.86931079]),\n",
       " 'test_mae': array([0.52082204, 0.52189573, 0.52227234, 0.5124031 , 0.52228699]),\n",
       " 'fit_time': (0.2511889934539795,\n",
       "  0.25397682189941406,\n",
       "  0.2724578380584717,\n",
       "  0.24985003471374512,\n",
       "  0.26448702812194824),\n",
       " 'test_time': (0.9160909652709961,\n",
       "  0.7501192092895508,\n",
       "  0.7518713474273682,\n",
       "  0.7315359115600586,\n",
       "  0.898292064666748)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# on crée / définit un lecteur en précisant l'échelle de notes\n",
    "reader = Reader(rating_scale = (0, 5))\n",
    "\n",
    "# on définit 'data' qui prendra comme paramètres les colonnes utilisateur, chanson et score (et le lecteur)\n",
    "data = Dataset.load_from_df(log[['user_id', 'song_id', 'count_score']], reader=reader)\n",
    "\n",
    "# on effectue une 'cross validation' avec ce 'data' et l'algo KNN basic\n",
    "cross_validate(KNNWithMeans(), data, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensuite les autre..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.02156   , 1.02214966, 1.02343231, 1.03110671, 1.0293117 ]),\n",
       " 'test_mae': array([0.61771391, 0.6191751 , 0.61788323, 0.61980289, 0.62024611]),\n",
       " 'fit_time': (0.12078094482421875,\n",
       "  0.18481993675231934,\n",
       "  0.19462823867797852,\n",
       "  0.19391202926635742,\n",
       "  0.17820382118225098),\n",
       " 'test_time': (0.9191980361938477,\n",
       "  0.7210559844970703,\n",
       "  0.8951308727264404,\n",
       "  0.7001557350158691,\n",
       "  0.8903698921203613)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN BASIC\n",
    "\n",
    "cross_validate(KNNBasic(), data, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.83140746, 0.84168616, 0.83390399, 0.83705431, 0.83373868]),\n",
       " 'test_mae': array([0.44893403, 0.45339807, 0.4463593 , 0.45041308, 0.44958305]),\n",
       " 'fit_time': (1.0558180809020996,\n",
       "  1.0849699974060059,\n",
       "  1.0774669647216797,\n",
       "  1.065384864807129,\n",
       "  1.099684238433838),\n",
       " 'test_time': (1.0611610412597656,\n",
       "  0.8946239948272705,\n",
       "  0.9698550701141357,\n",
       "  0.872157096862793,\n",
       "  0.9927947521209717)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN BASELINE\n",
    "\n",
    "cross_validate(KNNBaseline(), data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87371063, 0.86050918, 0.86127576, 0.85830653, 0.85687639]),\n",
       " 'test_mae': array([0.50440189, 0.50064981, 0.49920473, 0.49995817, 0.4971901 ]),\n",
       " 'fit_time': (0.3889899253845215,\n",
       "  0.4075331687927246,\n",
       "  0.390394926071167,\n",
       "  0.41718196868896484,\n",
       "  0.3983891010284424),\n",
       " 'test_time': (1.0694599151611328,\n",
       "  0.8497762680053711,\n",
       "  0.8397817611694336,\n",
       "  0.824321985244751,\n",
       "  0.9847052097320557)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN WITH Z SCORE\n",
    "\n",
    "cross_validate(KNNWithZScore(), data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.15950194, 1.15777458, 1.15118058, 1.14544566, 1.16207901]),\n",
       " 'test_mae': array([0.78071995, 0.77742258, 0.77529715, 0.77492037, 0.78557626]),\n",
       " 'fit_time': (0.30531978607177734,\n",
       "  0.3954896926879883,\n",
       "  0.34116315841674805,\n",
       "  0.35918211936950684,\n",
       "  0.39243102073669434),\n",
       " 'test_time': (0.3878488540649414,\n",
       "  0.5178060531616211,\n",
       "  0.34609103202819824,\n",
       "  0.5519559383392334,\n",
       "  0.36118102073669434)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NORMAL PREDICTOR\n",
    "\n",
    "cross_validate(NormalPredictor(), data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.76798493, 0.75895732, 0.77700649, 0.76376956, 0.75113828]),\n",
       " 'test_mae': array([0.40365573, 0.39997534, 0.40860107, 0.40416294, 0.39798417]),\n",
       " 'fit_time': (0.9371058940887451,\n",
       "  0.978165864944458,\n",
       "  0.9650669097900391,\n",
       "  0.9581189155578613,\n",
       "  0.9747271537780762),\n",
       " 'test_time': (0.46396613121032715,\n",
       "  0.3619987964630127,\n",
       "  0.43592309951782227,\n",
       "  0.44666600227355957,\n",
       "  0.32114672660827637)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE ONLY\n",
    "\n",
    "cross_validate(BaselineOnly(), data, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
